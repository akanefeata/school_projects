{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaa1648/school_projects/blob/main/_downloads/char_rnn_classification_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCngSNyfV6Xv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u0EsK__V6Xv"
      },
      "source": [
        "\n",
        "Classifying Names with a Character-Level RNN\n",
        "*********************************************\n",
        "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
        "\n",
        "We will be building and training a basic character-level RNN to classify\n",
        "words. A character-level RNN reads words as a series of characters -\n",
        "outputting a prediction and \"hidden state\" at each step, feeding its\n",
        "previous hidden state into each next step. We take the final prediction\n",
        "to be the output, i.e. which class the word belongs to.\n",
        "\n",
        "Specifically, we'll train on a few thousand surnames from 18 languages\n",
        "of origin, and predict which language a name is from based on the\n",
        "spelling:\n",
        "\n",
        "::\n",
        "\n",
        "    $ python predict.py Hinton\n",
        "    (-0.47) Scottish\n",
        "    (-1.52) English\n",
        "    (-3.57) Irish\n",
        "\n",
        "    $ python predict.py Schmidhuber\n",
        "    (-0.19) German\n",
        "    (-2.48) Czech\n",
        "    (-2.68) Dutch\n",
        "\n",
        "\n",
        "**Recommended Reading:**\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and\n",
        "understand Tensors:\n",
        "\n",
        "-  http://pytorch.org/ For installation instructions\n",
        "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
        "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
        "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
        "\n",
        "It would also be useful to know about RNNs and how they work:\n",
        "\n",
        "-  `The Unreasonable Effectiveness of Recurrent Neural\n",
        "   Networks <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n",
        "   shows a bunch of real life examples\n",
        "-  `Understanding LSTM\n",
        "   Networks <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n",
        "   is about LSTMs specifically but also informative about RNNs in\n",
        "   general\n",
        "\n",
        "Preparing the Data\n",
        "==================\n",
        "\n",
        ".. Note::\n",
        "   Download the data from\n",
        "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
        "   and extract it to the current directory.\n",
        "\n",
        "Included in the ``data/names`` directory are 18 text files named as\n",
        "\"[Language].txt\". Each file contains a bunch of names, one name per\n",
        "line, mostly romanized (but we still need to convert from Unicode to\n",
        "ASCII).\n",
        "\n",
        "We'll end up with a dictionary of lists of names per language,\n",
        "``{language: [names ...]}``. The generic variables \"category\" and \"line\"\n",
        "(for language and name in our case) are used for later extensibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2CeSyueV6Xw"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Belirtilen bir dosya yolundaki tüm dosyaları bulan bir fonksiyon\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "# 'data/names/' klasöründeki tüm .txt dosyalarını bul ve listele\n",
        "print(findFiles('data/names/*.txt'))\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "# ASCII harfler ve bazı özel karakterler; isim verisi temizliği için kullanılacak\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "\n",
        "# Unicode karakterleri ASCII'ye dönüştüren fonksiyon\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "# Örnek bir isimde Unicode'dan ASCII'ye dönüşümün çıktısını gösterir\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Her bir kategoriye (ülkeye) ait isimlerin tutulacağı sözlük\n",
        "category_lines = {}\n",
        "# Tüm kategorilerin (ülkelerin) tutulacağı liste\n",
        "all_categories = []\n",
        "\n",
        "\n",
        "# Belirtilen dosyadan satırları okuyan fonksiyon\n",
        "def readLines(filename):\n",
        "    # Dosyadaki her satırı okuyup Unicode'dan ASCII'ye dönüştürür\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "# 'data/names/' klasöründeki her dosya için işlemler\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    # Dosya adından kategori adını çıkar (örneğin, İngilizce için 'English')\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)  # Kategori listesini güncelle\n",
        "    lines = readLines(filename)      # Dosyadaki isimleri oku\n",
        "    category_lines[category] = lines  # Kategoriye ait isimleri sözlüğe ekle\n",
        "\n",
        "# Kategori (ülke) sayısını belirle\n",
        "n_categories = len(all_categories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp6wBML8V6Xw"
      },
      "source": [
        "Now we have ``category_lines``, a dictionary mapping each category\n",
        "(language) to a list of lines (names). We also kept track of\n",
        "``all_categories`` (just a list of languages) and ``n_categories`` for\n",
        "later reference.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW7aPXJiV6Xw"
      },
      "outputs": [],
      "source": [
        "# 'Italian' anahtarı altında bulunan ilk 5 ismi yazdır\n",
        "print(category_lines['Italian'][:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEZHEOlLV6Xx"
      },
      "source": [
        "Turning Names into Tensors\n",
        "--------------------------\n",
        "\n",
        "Now that we have all the names organized, we need to turn them into\n",
        "Tensors to make any use of them.\n",
        "\n",
        "To represent a single letter, we use a \"one-hot vector\" of size\n",
        "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
        "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
        "\n",
        "To make a word we join a bunch of those into a 2D matrix\n",
        "``<line_length x 1 x n_letters>``.\n",
        "\n",
        "That extra 1 dimension is because PyTorch assumes everything is in\n",
        "batches - we're just using a batch size of 1 here.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL_nVmlvV6Xx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# all_letters dizisinde belirtilen bir harfin indeksini bulan fonksiyon, örneğin \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Bir harfi <1 x n_letters> boyutunda bir tensöre çevirme fonksiyonu (örnek için)\n",
        "# Bu tensör bir \"one-hot\" vektörüdür, sadece belirli bir harfin konumunda 1 olur\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)  # <1 x n_letters> boyutunda sıfırlarla dolu bir tensör oluşturur\n",
        "    tensor[0][letterToIndex(letter)] = 1  # Harfin indeksine göre tensörde 1 olarak işaretler\n",
        "    return tensor\n",
        "\n",
        "# Bir metni <line_length x 1 x n_letters> boyutunda tensöre çevirme fonksiyonu\n",
        "# Bu tensör, harfleri \"one-hot\" vektörleri olarak temsil eden bir dizi içerir\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)  # Her harf için sıfırlardan oluşan bir tensör oluşturur\n",
        "    for li, letter in enumerate(line):  # Metindeki her harf için\n",
        "        tensor[li][0][letterToIndex(letter)] = 1  # Harfin indeksine göre tensörde 1 olarak işaretler\n",
        "    return tensor\n",
        "\n",
        "# 'J' harfini \"one-hot\" tensör olarak yazdır\n",
        "print(letterToTensor('J'))\n",
        "\n",
        "# 'Jones' kelimesini tensör boyutunda yazdır\n",
        "print(lineToTensor('Jones').size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0a-U9ziV6Xx"
      },
      "source": [
        "Creating the Network\n",
        "====================\n",
        "\n",
        "Before autograd, creating a recurrent neural network in Torch involved\n",
        "cloning the parameters of a layer over several timesteps. The layers\n",
        "held hidden state and gradients which are now entirely handled by the\n",
        "graph itself. This means you can implement a RNN in a very \"pure\" way,\n",
        "as regular feed-forward layers.\n",
        "\n",
        "This RNN module (mostly copied from `the PyTorch for Torch users\n",
        "tutorial <http://pytorch.org/tutorials/beginner/former_torchies/\n",
        "nn_tutorial.html#example-2-recurrent-net>`__)\n",
        "is just 2 linear layers which operate on an input and hidden state, with\n",
        "a LogSoftmax layer after the output.\n",
        "\n",
        ".. figure:: https://i.imgur.com/Z2xbySO.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QAhiOwaV6Xx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# RNN sınıfını tanımlıyoruz, nn.Module sınıfını miras alıyor\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()  # nn.Module'ın özelliklerini RNN'e aktarır\n",
        "\n",
        "        self.hidden_size = hidden_size  # Gizli katmanın boyutu\n",
        "\n",
        "        # Giriş ve gizli durumun birleşiminden gizli duruma geçiş katmanı\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "        # Giriş ve gizli durumun birleşiminden çıkışa geçiş katmanı\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "        # Çıkış katmanı için LogSoftmax aktivasyon fonksiyonu\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # İleri yayılım fonksiyonu, RNN'in giriş ve gizli durumu işleyerek çıktıyı üretmesini sağlar\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)  # Giriş ve gizli durumu birleştiriyoruz\n",
        "        hidden = self.i2h(combined)               # Yeni gizli durumu hesaplıyoruz\n",
        "        output = self.i2o(combined)               # Çıkış hesaplanıyor\n",
        "        output = self.softmax(output)             # LogSoftmax ile normalize ediliyor\n",
        "        return output, hidden                     # Çıktı ve yeni gizli durum döndürülüyor\n",
        "\n",
        "    # Başlangıç gizli durumu oluşturma fonksiyonu (başlangıçta tüm değerler 0)\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "# Gizli katman boyutu\n",
        "n_hidden = 128\n",
        "\n",
        "# RNN modelini başlatıyoruz, giriş boyutu n_letters, çıkış boyutu n_categories\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9GilaUtV6Xx"
      },
      "source": [
        "To run a step of this network we need to pass an input (in our case, the\n",
        "Tensor for the current letter) and a previous hidden state (which we\n",
        "initialize as zeros at first). We'll get back the output (probability of\n",
        "each language) and a next hidden state (which we keep for the next\n",
        "step).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMXYBM1qV6Xx"
      },
      "outputs": [],
      "source": [
        "# 'A' harfi için bir \"one-hot\" tensör oluşturuyoruz\n",
        "input = letterToTensor('A')\n",
        "\n",
        "# Gizli durumun başlangıç değeri olarak sıfırlardan oluşan bir tensör oluşturuyoruz\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "# RNN modeline 'A' harfi ve başlangıç gizli durumunu vererek çıktıyı ve bir sonraki gizli durumu elde ediyoruz\n",
        "output, next_hidden = rnn(input, hidden)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FMpu59dV6Xx"
      },
      "source": [
        "For the sake of efficiency we don't want to be creating a new Tensor for\n",
        "every step, so we will use ``lineToTensor`` instead of\n",
        "``letterToTensor`` and use slices. This could be further optimized by\n",
        "pre-computing batches of Tensors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2Ovf-d0V6Xx"
      },
      "outputs": [],
      "source": [
        "# 'Albert' ismini temsil eden bir tensör oluşturuyoruz.\n",
        "# Bu tensör, her harfi \"one-hot\" olarak temsil eden bir dizi tensörden oluşur.\n",
        "input = lineToTensor('Albert')\n",
        "\n",
        "# Gizli durumun başlangıç değeri olarak sıfırlardan oluşan bir tensör oluşturuyoruz\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "# İlk harfi (input[0]) ve gizli durumu RNN modeline vererek çıktıyı ve yeni gizli durumu alıyoruz\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "\n",
        "# Çıktıyı ekrana yazdırıyoruz; bu çıktı, modelin 'A' harfi ve başlangıç gizli durumu ile oluşturduğu tahmini temsil eder\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGQ0zJYUV6Xx"
      },
      "source": [
        "As you can see the output is a ``<1 x n_categories>`` Tensor, where\n",
        "every item is the likelihood of that category (higher is more likely).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKtYol66V6Xy"
      },
      "source": [
        "Training\n",
        "========\n",
        "Preparing for Training\n",
        "----------------------\n",
        "\n",
        "Before going into training we should make a few helper functions. The\n",
        "first is to interpret the output of the network, which we know to be a\n",
        "likelihood of each category. We can use ``Tensor.topk`` to get the index\n",
        "of the greatest value:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM2_Gmf3V6Xy"
      },
      "outputs": [],
      "source": [
        "# Modelin çıktısından kategori tahminini belirleyen fonksiyon\n",
        "def categoryFromOutput(output):\n",
        "    # En yüksek değeri ve onun indeksini buluyoruz (bu kategori tahminidir)\n",
        "    top_n, top_i = output.topk(1)  # En yüksek olasılık değerine sahip olanı seçiyoruz\n",
        "    category_i = top_i[0].item()   # İndeksi bir Python tamsayısına çeviriyoruz\n",
        "    return all_categories[category_i], category_i  # Kategori adını ve indeksini döndürüyoruz\n",
        "\n",
        "# Tahmin edilen kategori ve indeksini ekrana yazdırıyoruz\n",
        "print(categoryFromOutput(output))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iRiZBu0V6Xz"
      },
      "source": [
        "We will also want a quick way to get a training example (a name and its\n",
        "language):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHcUv55_V6Xz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Listeden rastgele bir öğe seçen fonksiyon\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "# Rastgele bir eğitim örneği oluşturan fonksiyon\n",
        "def randomTrainingExample():\n",
        "    # Kategoriler arasından rastgele bir kategori seçiyoruz\n",
        "    category = randomChoice(all_categories)\n",
        "\n",
        "    # Seçilen kategoriye ait isimler arasından rastgele bir isim seçiyoruz\n",
        "    line = randomChoice(category_lines[category])\n",
        "\n",
        "    # Kategori için indeks tensörünü oluşturuyoruz (kategori numarasını uzunluk türünde tensor yapıyoruz)\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "\n",
        "    # Seçilen ismi (line) tensöre çeviriyoruz\n",
        "    line_tensor = lineToTensor(line)\n",
        "\n",
        "    # Kategori adı, isim, kategori tensörü ve isim tensörünü döndürüyoruz\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "# 10 adet rastgele eğitim örneği oluşturup yazdırıyoruz\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category =', category, '/ line =', line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f0NfVf7V6Xz"
      },
      "source": [
        "Training the Network\n",
        "--------------------\n",
        "\n",
        "Now all it takes to train this network is show it a bunch of examples,\n",
        "have it make guesses, and tell it if it's wrong.\n",
        "\n",
        "For the loss function ``nn.NLLLoss`` is appropriate, since the last\n",
        "layer of the RNN is ``nn.LogSoftmax``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU7RVfr_V6Xz"
      },
      "outputs": [],
      "source": [
        "# Negatif Log-Likelihood (NLL) kayıp fonksiyonunu tanımlıyoruz\n",
        "criterion = nn.NLLLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54wT3MzwV6Xz"
      },
      "source": [
        "Each loop of training will:\n",
        "\n",
        "-  Create input and target tensors\n",
        "-  Create a zeroed initial hidden state\n",
        "-  Read each letter in and\n",
        "\n",
        "   -  Keep hidden state for next letter\n",
        "\n",
        "-  Compare final output to target\n",
        "-  Back-propagate\n",
        "-  Return the output and loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn9x2CvLV6Xz"
      },
      "outputs": [],
      "source": [
        "# Öğrenme oranını tanımlıyoruz; bu değer çok yüksek olursa model kararsızlaşabilir,\n",
        "# çok düşük olursa model öğrenim sürecini etkili bir şekilde gerçekleştiremeyebilir\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Modelin eğitimini gerçekleştiren fonksiyon\n",
        "def train(category_tensor, line_tensor):\n",
        "    # RNN için başlangıç gizli durumunu başlatıyoruz\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    # RNN modelinin gradyanlarını sıfırlıyoruz\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    # Girdi tensöründeki her harf için RNN modelini çalıştırıyoruz\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    # Çıktıyı ve kategori tensörünü kullanarak kaybı hesaplıyoruz\n",
        "    loss = criterion(output, category_tensor)\n",
        "\n",
        "    # Kayıp değerine göre gradyanları hesaplıyoruz\n",
        "    loss.backward()\n",
        "\n",
        "    # Öğrenme oranı ile çarpılan gradyanları, parametre değerlerine ekliyoruz\n",
        "    # Bu işlem, her parametrenin güncellenmesini sağlar\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "\n",
        "    # Son çıktıyı ve kayıp değerini döndürüyoruz\n",
        "    return output, loss.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMRkosGVV6Xz"
      },
      "source": [
        "Now we just have to run that with a bunch of examples. Since the\n",
        "``train`` function returns both the output and loss we can print its\n",
        "guesses and also keep track of loss for plotting. Since there are 1000s\n",
        "of examples we print only every ``print_every`` examples, and take an\n",
        "average of the loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNPmcxhpV6Xz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# Toplam iterasyon sayısı\n",
        "n_iters = 100000\n",
        "# Her 5000 iterasyonda çıktı vermek için ayarlama\n",
        "print_every = 5000\n",
        "# Her 1000 iterasyonda kayıp değerini grafiğe eklemek için ayarlama\n",
        "plot_every = 1000\n",
        "\n",
        "# Kayıpları takip etmek için bir liste\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Geçen süreyi hesaplayan fonksiyon\n",
        "def timeSince(since):\n",
        "    now = time.time()  # Şu anki zamanı al\n",
        "    s = now - since    # Başlangıç zamanından bu yana geçen süreyi hesapla\n",
        "    m = math.floor(s / 60)  # Dakika cinsinden süreyi hesapla\n",
        "    s -= m * 60  # Saniye cinsinden süreyi hesapla\n",
        "    return '%dm %ds' % (m, s)  # Dakika ve saniyeyi döndür\n",
        "\n",
        "start = time.time()  # Eğitim süresini başlat\n",
        "\n",
        "# Eğitim döngüsü\n",
        "for iter in range(1, n_iters + 1):\n",
        "    # Rastgele bir eğitim örneği oluştur\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    # Modeli eğit ve kaybı hesapla\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss  # Geçerli kaybı güncelle\n",
        "\n",
        "    # Belirli bir iterasyonda çıktı ver\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)  # Modelin tahminini al\n",
        "        # Doğruluğu kontrol et\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        # İterasyon numarasını, kaybı ve tahmini yazdır\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (\n",
        "            iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Geçerli kayıp ortalamasını kayıplar listesine ekle\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)  # Kayıp ortalamasını ekle\n",
        "        current_loss = 0  # Geçerli kaybı sıfırla\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH4Bnr7_V6Xz"
      },
      "source": [
        "Plotting the Results\n",
        "--------------------\n",
        "\n",
        "Plotting the historical loss from ``all_losses`` shows the network\n",
        "learning:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6PS47JEV6Xz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Yeni bir grafik oluştur\n",
        "plt.figure()\n",
        "# Kayıp değerlerini grafiğe çiz\n",
        "plt.plot(all_losses)\n",
        "\n",
        "# Eksenleri ayarlamak için ticker kullan\n",
        "plt.xlabel('Iterasyon (her 1000\\'de bir)')\n",
        "plt.ylabel('Kayıp (Loss)')\n",
        "plt.title('Eğitim Kaybı Grafiği')\n",
        "\n",
        "# Y ekseninde sayıları daha iyi göstermek için bir format belirle\n",
        "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
        "\n",
        "# Grafiği göster\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdjIlvwSV6Xz"
      },
      "source": [
        "Evaluating the Results\n",
        "======================\n",
        "\n",
        "To see how well the network performs on different categories, we will\n",
        "create a confusion matrix, indicating for every actual language (rows)\n",
        "which language the network guesses (columns). To calculate the confusion\n",
        "matrix a bunch of samples are run through the network with\n",
        "``evaluate()``, which is the same as ``train()`` minus the backprop.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAFEqPF2V6Xz"
      },
      "outputs": [],
      "source": [
        "# Doğru tahminleri takip etmek için bir karmaşa matrisini başlat\n",
        "confusion = torch.zeros(n_categories, n_categories)  # n_categories x n_categories boyutunda sıfırlardan oluşan bir matris\n",
        "n_confusion = 10000  # Değerlendirme için kullanılacak örnek sayısı\n",
        "\n",
        "# Bir satıra verilen çıktıyı döndürmek için fonksiyon\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.initHidden()  # RNN'in gizli durumunu başlat\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)  # Her harf için çıkışı hesapla\n",
        "\n",
        "    return output  # Son çıkışı döndür\n",
        "\n",
        "# Birçok örneği geçerek hangi tahminlerin doğru yapıldığını kaydet\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()  # Rastgele bir eğitim örneği al\n",
        "    output = evaluate(line_tensor)  # Örneği değerlendir\n",
        "    guess, guess_i = categoryFromOutput(output)  # Tahmin edilen kategoriyi al\n",
        "    category_i = all_categories.index(category)  # Gerçek kategorinin indeksini bul\n",
        "    confusion[category_i][guess_i] += 1  # Karmaşa matrisinde doğru tahmini güncelle\n",
        "\n",
        "# Her satırı kendi toplamına bölerek normalize et\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()  # Satır toplamına böl\n",
        "\n",
        "# Grafik ayarları\n",
        "fig = plt.figure()  # Yeni bir figür oluştur\n",
        "ax = fig.add_subplot(111)  # 1x1'lik bir ızgarada ilk alt grafiği oluştur\n",
        "cax = ax.matshow(confusion.numpy())  # Karmaşa matrisini görselleştir\n",
        "fig.colorbar(cax)  # Renk çubuğunu ekle\n",
        "\n",
        "# Eksen ayarları\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)  # X eksenindeki etiketleri ayarla\n",
        "ax.set_yticklabels([''] + all_categories)  # Y eksenindeki etiketleri ayarla\n",
        "\n",
        "# Her tikte etiket zorla\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))  # X eksenindeki her bir tike bir etiket yerleştir\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))  # Y eksenindeki her bir tike bir etiket yerleştir\n",
        "\n",
        "# Grafiği göster\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfDMVojpV6Xz"
      },
      "source": [
        "You can pick out bright spots off the main axis that show which\n",
        "languages it guesses incorrectly, e.g. Chinese for Korean, and Spanish\n",
        "for Italian. It seems to do very well with Greek, and very poorly with\n",
        "English (perhaps because of overlap with other languages).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsHSZQAyV6Xz"
      },
      "source": [
        "Running on User Input\n",
        "---------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO_HkKmdV6Xz"
      },
      "outputs": [],
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    # Kullanıcıdan alınan girdi satırını yazdır\n",
        "    print('\\n> %s' % input_line)\n",
        "    with torch.no_grad():  # Gradyan hesaplamasını kapat (eğitim aşaması değil)\n",
        "        output = evaluate(lineToTensor(input_line))  # Girdi satırını değerlendir\n",
        "\n",
        "        # En yüksek N kategoriyi al\n",
        "        topv, topi = output.topk(n_predictions, 1, True)  # En yüksek n_predictions değerini ve indekslerini al\n",
        "        predictions = []  # Tahminleri saklamak için bir liste oluştur\n",
        "\n",
        "        # Tahmin edilen kategorileri ve değerlerini yazdır\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()  # Tahmin edilen değer\n",
        "            category_index = topi[0][i].item()  # Tahmin edilen kategorinin indeksi\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))  # Değeri ve kategoriyi yazdır\n",
        "            predictions.append([value, all_categories[category_index]])  # Tahminleri listeye ekle\n",
        "\n",
        "# Örnek girdilerle tahminleri yap\n",
        "predict('Dovesky')  # 'Dovesky' ismi için tahmin yap\n",
        "predict('Jackson')  # 'Jackson' ismi için tahmin yap\n",
        "predict('Satoshi')  # 'Satoshi' ismi için tahmin yap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAobYMUvV6X0"
      },
      "source": [
        "The final versions of the scripts `in the Practical PyTorch\n",
        "repo <https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__\n",
        "split the above code into a few files:\n",
        "\n",
        "-  ``data.py`` (loads files)\n",
        "-  ``model.py`` (defines the RNN)\n",
        "-  ``train.py`` (runs training)\n",
        "-  ``predict.py`` (runs ``predict()`` with command line arguments)\n",
        "-  ``server.py`` (serve prediction as a JSON API with bottle.py)\n",
        "\n",
        "Run ``train.py`` to train and save the network.\n",
        "\n",
        "Run ``predict.py`` with a name to view predictions:\n",
        "\n",
        "::\n",
        "\n",
        "    $ python predict.py Hazaki\n",
        "    (-0.42) Japanese\n",
        "    (-1.39) Polish\n",
        "    (-3.51) Czech\n",
        "\n",
        "Run ``server.py`` and visit http://localhost:5533/Yourname to get JSON\n",
        "output of predictions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ0IxSqsV6X0"
      },
      "source": [
        "Exercises\n",
        "=========\n",
        "\n",
        "-  Try with a different dataset of line -> category, for example:\n",
        "\n",
        "   -  Any word -> language\n",
        "   -  First name -> gender\n",
        "   -  Character name -> writer\n",
        "   -  Page title -> blog or subreddit\n",
        "\n",
        "-  Get better results with a bigger and/or better shaped network\n",
        "\n",
        "   -  Add more linear layers\n",
        "   -  Try the ``nn.LSTM`` and ``nn.GRU`` layers\n",
        "   -  Combine multiple of these RNNs as a higher level network\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}